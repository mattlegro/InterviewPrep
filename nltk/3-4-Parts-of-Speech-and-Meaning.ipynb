{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts of Speech and Meaning (English Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"Cyprus, officially the Republic of Cyprus, is an island country in the Eastern Mediterranean and the third largest and third most populous island in the Mediterranean. Cyprus is located south of Turkey, west of Syria and Lebanon, northwest of Israel, north of Egypt, and southeast of Greece. Cyprus is a major tourist destination in the Mediterranean. With an advanced, high-income economy and a very high Human Development Index, the Republic of Cyprus has been a member of the Commonwealth since 1961 and was a founding member of the Non-Aligned Movement until it joined the European Union on 1 May 2004. On 1 January 2008, the Republic of Cyprus joined the eurozone.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cyprus, officially the republic of cyprus, is an island country in the eastern mediterranean and the third largest and third most populous island in the mediterranean.',\n",
       " 'cyprus is located south of turkey, west of syria and lebanon, northwest of israel, north of egypt, and southeast of greece.',\n",
       " 'cyprus is a major tourist destination in the mediterranean.',\n",
       " 'with an advanced, high-income economy and a very high human development index, the republic of cyprus has been a member of the commonwealth since 1961 and was a founding member of the non-aligned movement until it joined the european union on 1 may 2004. on 1 january 2008, the republic of cyprus joined the eurozone.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize, word_tokenize\n",
    "sentences = sent_tokenize(t.lower())\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cyprus',\n",
       " 'is',\n",
       " 'a',\n",
       " 'major',\n",
       " 'tourist',\n",
       " 'destination',\n",
       " 'in',\n",
       " 'the',\n",
       " 'mediterranean',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(sentences[2])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cyprus', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('major', 'JJ'),\n",
       " ('tourist', 'NN'),\n",
       " ('destination', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('mediterranean', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "tags = pos_tag(tokens)\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access documentation for tags, for example for `NN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n"
     ]
    }
   ],
   "source": [
    "import nltk.help\n",
    "nltk.help.upenn_tagset('NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Word senses (for homonyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet is a lexical database for the English language in the form of a semantic graph. \n",
    "\n",
    "WordNet groups English words into sets of synonyms called synsets, provides short definitions and usage examples, and records a number of relations among these synonym sets or their members.\n",
    "\n",
    "NLTK provides an interface to the WordNet API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('homo.n.02'),\n",
       " Synset('human.a.01'),\n",
       " Synset('human.a.02'),\n",
       " Synset('human.a.03')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'any living or extinct member of the family Hominidae characterized by superior intelligence, articulate speech, and erect carriage'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('human')[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'characteristic of humanity'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('human')[1].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('homo.n.02')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human = wn.synsets('Human', pos=wn.NOUN)[0]\n",
    "human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('hominid.n.01')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human.hypernyms() # A hypernym is a word with a broad meaning constituting a category into which words with more specific meanings fall; a superordinate. For example, colour is a hypernym of red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('homo_erectus.n.01'),\n",
       " Synset('homo_habilis.n.01'),\n",
       " Synset('homo_sapiens.n.01'),\n",
       " Synset('homo_soloensis.n.01'),\n",
       " Synset('neandertal_man.n.01'),\n",
       " Synset('rhodesian_man.n.01'),\n",
       " Synset('world.n.08')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('bicycle.n.01')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike = wn.synsets('bicycle')[0]\n",
    "bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('female_child.n.01')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "girl = wn.synsets('girl')[1]\n",
    "girl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34782608695652173"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike.wup_similarity(human) # The Wu-Palmer metric (WUP) is a measure of similarity based on distance in the graph. There are many other metrics too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5217391304347826"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "girl.wup_similarity(human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['girl',\n",
       " 'miss',\n",
       " 'missy',\n",
       " 'young_lady',\n",
       " 'young_woman',\n",
       " 'fille',\n",
       " 'female_child',\n",
       " 'girl',\n",
       " 'little_girl',\n",
       " 'daughter',\n",
       " 'girl',\n",
       " 'girlfriend',\n",
       " 'girl',\n",
       " 'lady_friend',\n",
       " 'girl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms = []\n",
    "for syn in wn.synsets('girl'):\n",
    "    for lemma in syn.lemmas(): #  A lemma is basically the dictionary form or base form of a word, as opposed to the various inflected forms of a word. \n",
    "        synonyms.append(lemma.name())\n",
    "synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['male_child', 'boy', 'son', 'boy']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antonyms = []\n",
    "for syn in wn.synsets(\"girl\"):\n",
    "    for l in syn.lemmas():\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "antonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chunking and Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of chunking is to divide a sentence into chunks. Usually each chunk contains a **head** and optionally additionally words and modifiers. Examples of chunks include noun groups and verb groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import RegexpParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a chunker, we need to first define a **chunk grammar**, consisting of rules that indicate how sentences should be chunked. \n",
    "\n",
    "We can define a simple grammar for a noun phrase (NP) chunker with a single regular-expression rule. This rule says that an NP chunk should be formed whenever the chunker finds an optional determiner (`DT`) followed by any number of adjectives (`JJ`) and then a noun (`NN`).\n",
    "\n",
    "Note how grammatical structures which are not noun phrases are not chunked, which is totally fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Ghostscript executable isn't found.\n",
      "See http://web.mit.edu/ghostscript/www/Install.htm\n",
      "If you're using a Mac, you can try installing\n",
      "https://docs.brew.sh/Installation then `brew install ghostscript`\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\esmba\\miniconda3\\envs\\CohereInterview\\lib\\site-packages\\nltk\\tree.py:802\u001b[0m, in \u001b[0;36mTree._repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    800\u001b[0m     subprocess\u001b[39m.\u001b[39mcall(\n\u001b[0;32m    801\u001b[0m         [\n\u001b[1;32m--> 802\u001b[0m             find_binary(\n\u001b[0;32m    803\u001b[0m                 \u001b[39m'\u001b[39;49m\u001b[39mgs\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    804\u001b[0m                 binary_names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mgswin32c.exe\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mgswin64c.exe\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    805\u001b[0m                 env_vars\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mPATH\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    806\u001b[0m                 verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    807\u001b[0m             )\n\u001b[0;32m    808\u001b[0m         ]\n\u001b[0;32m    809\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-q -dEPSCrop -sDEVICE=png16m -r90 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -dSAFER -dBATCH -dNOPAUSE -sOutputFile=\u001b[39m\u001b[39m{0:}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{1:}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    810\u001b[0m             out_path, in_path\n\u001b[0;32m    811\u001b[0m         )\u001b[39m.\u001b[39msplit()\n\u001b[0;32m    812\u001b[0m     )\n\u001b[0;32m    813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\esmba\\miniconda3\\envs\\CohereInterview\\lib\\site-packages\\nltk\\internals.py:695\u001b[0m, in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_binary\u001b[39m(\n\u001b[0;32m    687\u001b[0m     name,\n\u001b[0;32m    688\u001b[0m     path_to_bin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    693\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    694\u001b[0m ):\n\u001b[1;32m--> 695\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\n\u001b[0;32m    696\u001b[0m         find_binary_iter(\n\u001b[0;32m    697\u001b[0m             name, path_to_bin, env_vars, searchpath, binary_names, url, verbose\n\u001b[0;32m    698\u001b[0m         )\n\u001b[0;32m    699\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\esmba\\miniconda3\\envs\\CohereInterview\\lib\\site-packages\\nltk\\internals.py:680\u001b[0m, in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[39mSearch for a file to be used by nltk.\u001b[39;00m\n\u001b[0;32m    671\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39m:param verbose: Whether or not to print path when a file is found.\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 680\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m find_file_iter(\n\u001b[0;32m    681\u001b[0m     path_to_bin \u001b[39mor\u001b[39;00m name, env_vars, searchpath, binary_names, url, verbose\n\u001b[0;32m    682\u001b[0m ):\n\u001b[0;32m    683\u001b[0m     \u001b[39myield\u001b[39;00m file\n",
      "File \u001b[1;32mc:\\Users\\esmba\\miniconda3\\envs\\CohereInterview\\lib\\site-packages\\nltk\\internals.py:639\u001b[0m, in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    638\u001b[0m div \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m75\u001b[39m\n\u001b[1;32m--> 639\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (div, msg, div))\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\esmba\\miniconda3\\envs\\CohereInterview\\lib\\site-packages\\IPython\\core\\formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    342\u001b[0m     method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n\u001b[0;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m         \u001b[39mreturn\u001b[39;00m method()\n\u001b[0;32m    345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\esmba\\miniconda3\\envs\\CohereInterview\\lib\\site-packages\\nltk\\tree.py:819\u001b[0m, in \u001b[0;36mTree._repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    814\u001b[0m     pre_error_message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe Ghostscript executable isn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt found.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    815\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39mSee http://web.mit.edu/ghostscript/www/Install.htm\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39mIf you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre using a Mac, you can try installing\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39mhttps://docs.brew.sh/Installation then `brew install ghostscript`\u001b[39m\u001b[39m\"\u001b[39m)                \n\u001b[0;32m    818\u001b[0m     \u001b[39mprint\u001b[39m(pre_error_message, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m--> 819\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m\n\u001b[0;32m    821\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(out_path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m sr:\n\u001b[0;32m    822\u001b[0m     res \u001b[39m=\u001b[39m sr\u001b[39m.\u001b[39mread()\n",
      "\u001b[1;31mLookupError\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [Tree('NP', [('cyprus', 'NN')]), ('is', 'VBZ'), Tree('NP', [('a', 'DT'), ('major', 'JJ'), ('tourist', 'NN')]), Tree('NP', [('destination', 'NN')]), ('in', 'IN'), Tree('NP', [('the', 'DT'), ('mediterranean', 'NN')]), ('.', '.')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunker = RegexpParser(grammar)\n",
    "result = chunker.parse(tags)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of entity recogintion is to detect entities such as Person, Location, Time, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Ghostscript executable isn't found.\n",
      "See http://web.mit.edu/ghostscript/www/Install.htm\n",
      "If you're using a Mac, you can try installing\n",
      "https://docs.brew.sh/Installation then `brew install ghostscript`\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\esmba\\miniconda3\\envs\\CohereInterview\\lib\\site-packages\\nltk\\tree.py:802\u001b[0m, in \u001b[0;36mTree._repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    800\u001b[0m     subprocess\u001b[39m.\u001b[39mcall(\n\u001b[0;32m    801\u001b[0m         [\n\u001b[1;32m--> 802\u001b[0m             find_binary(\n\u001b[0;32m    803\u001b[0m                 \u001b[39m'\u001b[39;49m\u001b[39mgs\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    804\u001b[0m                 binary_names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mgswin32c.exe\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mgswin64c.exe\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    805\u001b[0m                 env_vars\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mPATH\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    806\u001b[0m                 verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    807\u001b[0m             )\n\u001b[0;32m    808\u001b[0m         ]\n\u001b[0;32m    809\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-q -dEPSCrop -sDEVICE=png16m -r90 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -dSAFER -dBATCH -dNOPAUSE -sOutputFile=\u001b[39m\u001b[39m{0:}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{1:}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    810\u001b[0m             out_path, in_path\n\u001b[0;32m    811\u001b[0m         )\u001b[39m.\u001b[39msplit()\n\u001b[0;32m    812\u001b[0m     )\n\u001b[0;32m    813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\esmba\\miniconda3\\envs\\CohereInterview\\lib\\site-packages\\nltk\\internals.py:695\u001b[0m, in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_binary\u001b[39m(\n\u001b[0;32m    687\u001b[0m     name,\n\u001b[0;32m    688\u001b[0m     path_to_bin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    693\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    694\u001b[0m ):\n\u001b[1;32m--> 695\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\n\u001b[0;32m    696\u001b[0m         find_binary_iter(\n\u001b[0;32m    697\u001b[0m             name, path_to_bin, env_vars, searchpath, binary_names, url, verbose\n\u001b[0;32m    698\u001b[0m         )\n\u001b[0;32m    699\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\esmba\\miniconda3\\envs\\CohereInterview\\lib\\site-packages\\nltk\\internals.py:680\u001b[0m, in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[39mSearch for a file to be used by nltk.\u001b[39;00m\n\u001b[0;32m    671\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39m:param verbose: Whether or not to print path when a file is found.\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 680\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m find_file_iter(\n\u001b[0;32m    681\u001b[0m     path_to_bin \u001b[39mor\u001b[39;00m name, env_vars, searchpath, binary_names, url, verbose\n\u001b[0;32m    682\u001b[0m ):\n\u001b[0;32m    683\u001b[0m     \u001b[39myield\u001b[39;00m file\n",
      "File \u001b[1;32mc:\\Users\\esmba\\miniconda3\\envs\\CohereInterview\\lib\\site-packages\\nltk\\internals.py:639\u001b[0m, in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    638\u001b[0m div \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m75\u001b[39m\n\u001b[1;32m--> 639\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (div, msg, div))\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\esmba\\miniconda3\\envs\\CohereInterview\\lib\\site-packages\\IPython\\core\\formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    342\u001b[0m     method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n\u001b[0;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m         \u001b[39mreturn\u001b[39;00m method()\n\u001b[0;32m    345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\esmba\\miniconda3\\envs\\CohereInterview\\lib\\site-packages\\nltk\\tree.py:819\u001b[0m, in \u001b[0;36mTree._repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    814\u001b[0m     pre_error_message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe Ghostscript executable isn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt found.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    815\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39mSee http://web.mit.edu/ghostscript/www/Install.htm\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39mIf you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre using a Mac, you can try installing\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39mhttps://docs.brew.sh/Installation then `brew install ghostscript`\u001b[39m\u001b[39m\"\u001b[39m)                \n\u001b[0;32m    818\u001b[0m     \u001b[39mprint\u001b[39m(pre_error_message, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m--> 819\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m\n\u001b[0;32m    821\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(out_path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m sr:\n\u001b[0;32m    822\u001b[0m     res \u001b[39m=\u001b[39m sr\u001b[39m.\u001b[39mread()\n",
      "\u001b[1;31mLookupError\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('cyprus', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('major', 'JJ'), ('tourist', 'NN'), ('destination', 'NN'), ('in', 'IN'), ('the', 'DT'), ('mediterranean', 'NN'), ('.', '.')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.chunk import ne_chunk # ne = named entity\n",
    "ne_chunk(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note `ne_chunk` was unable to detect any entities in our sentence. That is because it is quite limited, being able to recognize only the following entities: \n",
    "> FACILITY, GPE (Geo-Political Entity), GSP (Geo-Socio-Political group), LOCATION, ORGANIZATION, PERSON "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
